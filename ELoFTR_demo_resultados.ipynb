{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vcYjx3HFUcw"
      },
      "source": [
        "# ELoFTR demo resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CChK3ciimW4r"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone https://github.com/zju3dv/EfficientLoFTR.git\n",
        "%cd EfficientLoFTR\n",
        "!pip install opencv-python torch torchvision yacs matplotlib scipy tqdm --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.stats import entropy\n",
        "\n",
        "# Ajusta el path\n",
        "from omegaconf import OmegaConf\n",
        "from src.loftr import LoFTR\n",
        "\n",
        "config = OmegaConf.load(\"configs/efficientloftr/loftr_realistic.ini\")\n",
        "matcher = LoFTR(config).eval().to(\"cpu\")\n",
        "\n",
        "def extract_eff_loftr(img1, img2):\n",
        "    g1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)[None][None]\n",
        "    g2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)[None][None]\n",
        "    t1 = torch.from_numpy(g1 / 255.).float().to(\"cpu\")\n",
        "    t2 = torch.from_numpy(g2 / 255.).float().to(\"cpu\")\n",
        "    with torch.no_grad():\n",
        "        data = {\"image0\": t1, \"image1\": t2}\n",
        "        matches = matcher(data)\n",
        "    kp1 = matches[\"keypoints0\"].cpu().numpy()\n",
        "    kp2 = matches[\"keypoints1\"].cpu().numpy()\n",
        "    desc1 = matches[\"descriptors0\"].cpu().numpy()\n",
        "    desc2 = matches[\"descriptors1\"].cpu().numpy()\n",
        "    return kp1, desc1, kp2, desc2\n",
        "\n",
        "def spatial_entropy(kps, shape, grid_size=4):\n",
        "    H, W = shape[:2]\n",
        "    heatmap = np.zeros((grid_size, grid_size))\n",
        "    for x, y in kps:\n",
        "        c = min(int(x / W * grid_size), grid_size - 1)\n",
        "        r = min(int(y / H * grid_size), grid_size - 1)\n",
        "        heatmap[r, c] += 1\n",
        "    p = heatmap.flatten()\n",
        "    p /= (p.sum() + 1e-8)\n",
        "    return entropy(p)\n",
        "\n",
        "def match_metrics_draw(kp1, desc1, kp2, desc2, img1, img2, save_path):\n",
        "    d = cdist(desc1, desc2, metric='euclidean')\n",
        "    idx = np.argmin(d, axis=1)\n",
        "    num = len(idx)\n",
        "    eff = num / (len(desc1) + 1e-8)\n",
        "    avgd = float(d[np.arange(num), idx].mean())\n",
        "    se = spatial_entropy(kp1[idx], img1.shape)\n",
        "\n",
        "    # draw\n",
        "    h1, w1 = img1.shape[:2]\n",
        "    h2, w2 = img2.shape[:2]\n",
        "    out = np.zeros((max(h1,h2), w1 + w2, 3), dtype=np.uint8)\n",
        "    out[:h1, :w1] = img1\n",
        "    out[:h2, w1:] = img2\n",
        "    for i, j in enumerate(idx):\n",
        "        p1 = tuple(np.round(kp1[i]).astype(int))\n",
        "        p2 = tuple(np.round(kp2[j]).astype(int) + np.array([w1,0]))\n",
        "        cv2.line(out, p1, p2, (0,255,0), 1)\n",
        "    cv2.imwrite(save_path, out)\n",
        "\n",
        "    return num, eff, avgd, se\n"
      ],
      "metadata": {
        "id": "t3L124mRcyLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Iterar sobre pares day / night\n",
        "BASE = '/content/drive/MyDrive/pruebas-pfc-2025/aachen_dataset/day'\n",
        "OUT = '/content/efficientloftr_day'\n",
        "os.makedirs(OUT, exist_ok=True)\n",
        "results = []\n",
        "\n",
        "for pair in tqdm(sorted(os.listdir(BASE))):\n",
        "    p = os.path.join(BASE, pair)\n",
        "    i1 = os.path.join(p, 'img1.png')\n",
        "    i2 = os.path.join(p, 'img2.png')\n",
        "    if os.path.exists(i1) and os.path.exists(i2):\n",
        "        img1 = cv2.imread(i1)\n",
        "        img2 = cv2.imread(i2)\n",
        "        kp1, desc1, kp2, desc2 = extract_eff_loftr(img1, img2)\n",
        "        num, eff, avgd, se = match_metrics_draw(kp1, desc1, kp2, desc2, img1, img2, os.path.join(OUT, f\"{pair}_m.png\"))\n",
        "        results.append({\n",
        "            'pair': pair,\n",
        "            'num_matches': num,\n",
        "            'efficiency': round(eff, 4),\n",
        "            'avg_distance': round(avgd, 4),\n",
        "            'spatial_entropy': round(se, 4)\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(os.path.join(OUT, 'efficientloftr_day.csv'), index=False)\n",
        "print(\"Resultados guardados en:\", OUT)"
      ],
      "metadata": {
        "id": "6YsbqXUJc06c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}