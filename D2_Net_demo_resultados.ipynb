{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# D2-NET RESULTADOS (demo colab)"
      ],
      "metadata": {
        "id": "VKJ4kDsna_K5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drive"
      ],
      "metadata": {
        "id": "XpukJc_KiWAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWpaAb5IiXmR",
        "outputId": "afeb822f-165e-46e5-9b35-96b4bf5400c2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probar si se montó correctamente"
      ],
      "metadata": {
        "id": "lxo4nL7vpp1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/pruebas-pfc-2025/aachen_dataset/day/pair_01/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zt9lHYnibU6",
        "outputId": "4f72cdf5-e75f-4198-fc60-62a671aa3313"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img1.png  img2.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Instalar dependencias\n",
        "!pip install opencv-python matplotlib numpy scipy tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Dh4Ezj-rV7i",
        "outputId": "ce4c725a-2487-471b-ccc9-67db775bbb28"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Clonar repositorio, y cambiar el nombre a la carpeta a d2net para que pueda ser leido\n",
        "\n",
        "!git clone https://github.com/mihaidusmanu/d2-net.git\n",
        "!mv d2-net d2net\n",
        "%cd d2net\n",
        "!mkdir -p models\n",
        "!wget https://dusmanu.com/files/d2-net/d2_tf.pth -O models/d2_tf.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDFm9hj9Zuuw",
        "outputId": "de4048f6-93a0-4352-e23d-b8b131e307f9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'd2-net'...\n",
            "remote: Enumerating objects: 223, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 223 (delta 51), reused 43 (delta 43), pack-reused 155 (from 1)\u001b[K\n",
            "Receiving objects: 100% (223/223), 2.35 MiB | 6.16 MiB/s, done.\n",
            "Resolving deltas: 100% (108/108), done.\n",
            "/content/d2net/d2net\n",
            "--2025-06-19 03:09:52--  https://dusmanu.com/files/d2-net/d2_tf.pth\n",
            "Resolving dusmanu.com (dusmanu.com)... 142.132.238.25\n",
            "Connecting to dusmanu.com (dusmanu.com)|142.132.238.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30545768 (29M) [application/octet-stream]\n",
            "Saving to: ‘models/d2_tf.pth’\n",
            "\n",
            "models/d2_tf.pth    100%[===================>]  29.13M  12.0MB/s    in 2.4s    \n",
            "\n",
            "2025-06-19 03:09:56 (12.0 MB/s) - ‘models/d2_tf.pth’ saved [30545768/30545768]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Cargar librerías y preparar modelo\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.stats import entropy\n",
        "\n",
        "import torch\n",
        "from d2net.lib.model_test import D2Net\n",
        "from d2net.lib.utils import preprocess_image\n",
        "from d2net.lib.pyramid import process_multiscale\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "model = D2Net(model_file='models/d2_tf.pth', use_relu=True, use_cuda=False).to(device).eval()\n",
        "\n",
        "# Funciones auxiliares\n",
        "def extract_d2net_features(image):\n",
        "    image = image.astype('float32') / 255.\n",
        "    image = preprocess_image(image)  # esto devuelve numpy\n",
        "    image = torch.from_numpy(image).unsqueeze(0)  # <- convertir a Tensor y agregar dimensión batch\n",
        "    #if torch.cuda.is_available():\n",
        "       # image = image.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        keypoints, scores, descriptors = process_multiscale(image, model)\n",
        "\n",
        "    # Seleccionar los Top-N keypoints por score\n",
        "    #if len(scores) > top_n:\n",
        "    #    idx = np.argsort(scores)[::-1][:top_n]\n",
        "    #    keypoints = keypoints[idx]\n",
        "    #    descriptors = descriptors[idx]\n",
        "\n",
        "    return keypoints, descriptors\n",
        "\n",
        "def match_features(desc1, desc2):\n",
        "    distances = cdist(desc1, desc2, metric='euclidean')\n",
        "    indices = np.argmin(distances, axis=1)\n",
        "    min_distances = distances[np.arange(distances.shape[0]), indices]\n",
        "    matches = np.stack((np.arange(len(indices)), indices), axis=1)\n",
        "    return matches, min_distances\n",
        "\n",
        "def spatial_entropy(keypoints, image_shape, grid_size=4):\n",
        "    H, W = image_shape[:2]\n",
        "    heatmap = np.zeros((grid_size, grid_size))\n",
        "    for kp in keypoints:\n",
        "        x, y = kp[:2]\n",
        "        col = min(int(x / W * grid_size), grid_size - 1)\n",
        "        row = min(int(y / H * grid_size), grid_size - 1)\n",
        "        heatmap[row, col] += 1\n",
        "    prob = heatmap.flatten()\n",
        "    prob = prob / (prob.sum() + 1e-8)\n",
        "    return entropy(prob)\n",
        "\n",
        "def draw_matches(img1, kp1, img2, kp2, matches, save_path):\n",
        "    h1, w1 = img1.shape[:2]\n",
        "    h2, w2 = img2.shape[:2]\n",
        "    new_img = np.zeros((max(h1, h2), w1 + w2, 3), dtype=np.uint8)\n",
        "    new_img[:h1, :w1] = img1\n",
        "    new_img[:h2, w1:] = img2\n",
        "    for match in matches:\n",
        "        pt1 = tuple(np.round(kp1[match[0], :2]).astype(int))\n",
        "        pt2 = tuple(np.round(kp2[match[1], :2]).astype(int) + np.array([w1, 0]))\n",
        "        cv2.line(new_img, pt1, pt2, (0, 255, 0), 1)\n",
        "    cv2.imwrite(save_path, new_img)\n"
      ],
      "metadata": {
        "id": "43JcpWnxr2dI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Procesar todas las imágenes del conjunto DAY\n",
        "\n",
        "# Ruta base en Drive\n",
        "base_path = '/content/drive/MyDrive/pruebas-pfc-2025/aachen_dataset/day'\n",
        "result_dir = '/content/d2net_day_results'\n",
        "os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "csv_data = []\n",
        "top_n=500\n",
        "# Iterar sobre cada par\n",
        "for folder in tqdm(sorted(os.listdir(base_path))):\n",
        "    pair_path = os.path.join(base_path, folder)\n",
        "    img1_path = os.path.join(pair_path, 'img1.png')\n",
        "    img2_path = os.path.join(pair_path, 'img2.png')\n",
        "\n",
        "    if os.path.exists(img1_path) and os.path.exists(img2_path):\n",
        "        img1 = cv2.imread(img1_path)\n",
        "        img2 = cv2.imread(img2_path)\n",
        "\n",
        "        kp1, desc1 = extract_d2net_features(img1)\n",
        "        kp2, desc2 = extract_d2net_features(img2)\n",
        "\n",
        "        matches, distances = match_features(desc1, desc2)\n",
        "\n",
        "        # Métricas\n",
        "        num_matches = len(matches)\n",
        "        efficiency = num_matches / (min(len(desc1), len(desc2)) + 1e-8)\n",
        "        avg_distance = float(np.mean(distances))\n",
        "\n",
        "        kp1 = np.array(kp1)\n",
        "        matched_kp1 = kp1[matches[:, 0]]\n",
        "\n",
        "        spatial_ent = spatial_entropy(matched_kp1, img1.shape)\n",
        "\n",
        "        output_img_path = os.path.join(result_dir, f'{folder}_matches.png')\n",
        "        draw_matches(img1, kp1, img2, kp2, matches, output_img_path)\n",
        "\n",
        "        csv_data.append({\n",
        "            'pair': folder,\n",
        "            'num_matches': num_matches,\n",
        "            'efficiency': round(efficiency, 4),\n",
        "            'avg_distance': round(avg_distance, 4),\n",
        "            'spatial_entropy': round(spatial_ent, 4)\n",
        "        })\n",
        "\n",
        "# Guardar CSV\n",
        "df = pd.DataFrame(csv_data)\n",
        "csv_path = os.path.join(result_dir, 'd2net_day_results.csv')\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Proceso completado. Resultados guardados en:\\n{csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A_4HSYYr4W3",
        "outputId": "f57d454e-02e0-49d0-88e3-150f4e5b275d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [28:39<00:00, 343.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proceso completado. Resultados guardados en:\n",
            "/content/d2net_day_results/d2net_day_results.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/meminfo | grep Mem\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWHco3QCItlM",
        "outputId": "bf99362e-e195-4ca3-e086-80a172dfec20"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MemTotal:       13289424 kB\n",
            "MemFree:         6535876 kB\n",
            "MemAvailable:   11101016 kB\n"
          ]
        }
      ]
    }
  ]
}